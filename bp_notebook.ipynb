{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42ff2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, instrument, note, chord, stream\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from collections import Counter\n",
    "from fractions import Fraction\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import sklearn\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1147f32",
   "metadata": {},
   "source": [
    "parse_MIDI.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4654cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi_file(file_name):\n",
    "\n",
    "    midi_sample = None\n",
    "    try:\n",
    "        midi_sample = converter.parse(file_name)\n",
    "    except OSError as e:\n",
    "        print('\\nERROR loading MIDI file in load_midi_file()')\n",
    "        print(e)\n",
    "        quit()\n",
    "    return midi_sample\n",
    "\n",
    "\n",
    "def parse_midi_file(folder_path):\n",
    "\n",
    "    notes_piano = []\n",
    "    metadata_piano = {\n",
    "        \"note_count\": 0,\n",
    "        \"chord_count\": 0,\n",
    "        \"rest\": 0,\n",
    "        \"else_count\": 0\n",
    "    }\n",
    "\n",
    "    all_names = []\n",
    "\n",
    "    for oneFile in os.listdir(folder_path):\n",
    "        if oneFile.endswith(\".mid\"):\n",
    "            all_names.append(oneFile)\n",
    "            midi_file = folder_path+oneFile\n",
    "            midi_sample = load_midi_file(midi_file)\n",
    "            instruments = instrument.partitionByInstrument(midi_sample)\n",
    "\n",
    "            for part in instruments.parts:\n",
    "\n",
    "                if 'Piano' in str(part):\n",
    "                    print('parsing PIANO', part)\n",
    "\n",
    "                    notes_to_parse = part.recurse()\n",
    "                    last_offset = 0\n",
    "\n",
    "                    # note  -> n_pitch_quarterLength_deltaOffset\n",
    "                    # chord -> c_pitch_quarterLength_deltaOffset\n",
    "                    # rest  -> r_quarterLength_deltaOffset\n",
    "\n",
    "                    elems_count = 0\n",
    "                    for element in notes_to_parse:\n",
    "                        elems_count += 1\n",
    "                        if isinstance(element, note.Note):\n",
    "                            delta_offset = Fraction(element.offset) - last_offset\n",
    "                            last_offset = Fraction(element.offset)\n",
    "\n",
    "                            notes_piano.append('n_'+str(element.pitch)+'_'+str(element.duration.quarterLength)+'_'+str(delta_offset))\n",
    "                            metadata_piano[\"note_count\"] += 1\n",
    "\n",
    "                        elif isinstance(element, chord.Chord):\n",
    "                            delta_offset = Fraction(element.offset) - last_offset\n",
    "                            last_offset = Fraction(element.offset)\n",
    "\n",
    "                            chord_ = '.'.join(str(n) for n in element.pitches)\n",
    "                            notes_piano.append('c_' + chord_ + '_' + str(element.duration.quarterLength)+'_'+str(delta_offset))\n",
    "                            metadata_piano[\"chord_count\"] += 1\n",
    "\n",
    "                        elif isinstance(element, note.Rest):\n",
    "                            delta_offset = Fraction(element.offset) - last_offset\n",
    "                            last_offset = Fraction(element.offset)\n",
    "\n",
    "                            notes_piano.append('r_' + str(element.duration.quarterLength)+'_'+str(delta_offset))\n",
    "                            metadata_piano[\"rest\"] += 1\n",
    "                        else:\n",
    "                            metadata_piano[\"else_count\"] += 1\n",
    "                    print('^elems_count:', elems_count)\n",
    "    print('MIDI dataset:\\n', all_names)\n",
    "    return notes_piano, metadata_piano\n",
    "\n",
    "\n",
    "def average_f(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "\n",
    "def remove_values_from_list(the_list, val):\n",
    "   return [value for value in the_list if value != val]\n",
    "\n",
    "\n",
    "def cut_notes(uncut_notes, metadata, cuts):\n",
    "    notes = uncut_notes\n",
    "    stop_flag = False\n",
    "\n",
    "    for i in range(cuts):\n",
    "        count_num = Counter(notes)\n",
    "        Recurrence = list(count_num.values())\n",
    "\n",
    "        pitchnames = set(notes)\n",
    "        note_to_int_before = dict((note_var, number) for number, note_var in enumerate(pitchnames))\n",
    "        avg_r = round(average_f(Recurrence), 2)\n",
    "\n",
    "        print('\\nnumber of notes before:', len(notes))\n",
    "        print('number of unique notes before:', len(note_to_int_before))\n",
    "        print(\"average recurrence for a note in notes:\", avg_r)\n",
    "        print(\"most frequent note in notes appeared:\", max(Recurrence), \"times\")\n",
    "        print(\"least frequent note in notes appeared:\", min(Recurrence), \"time/s\")\n",
    "\n",
    "        # if average recurrence is more then a 100, @param avg_r is set to 100 and this will be final eliminating\n",
    "        if round(avg_r) >= 100:\n",
    "            avg_r = 100\n",
    "            stop_flag = True\n",
    "\n",
    "        # getting a list of elements that appear less then avarage element does\n",
    "        rare_note = []\n",
    "        cn_items = count_num.items()\n",
    "        for index, (key, value) in enumerate(cn_items):\n",
    "            if value < round(avg_r):\n",
    "                m = key\n",
    "                rare_note.append(m)\n",
    "        print(f'number of notes occuring less than {round(avg_r)} times:', len(rare_note))\n",
    "\n",
    "        # eleminating those elements\n",
    "        for element in notes:\n",
    "            if element in rare_note:\n",
    "                len_before = len(notes)\n",
    "                notes = remove_values_from_list(notes, element)\n",
    "                elements_removed = len_before - len(notes)\n",
    "                if element[:1] == 'n':\n",
    "                    metadata['note_count'] -= elements_removed\n",
    "                elif element[:1] == 'c':\n",
    "                    metadata['chord_count'] -= elements_removed\n",
    "                elif element[:1] == 'r':\n",
    "                    metadata['rest'] -= elements_removed\n",
    "\n",
    "        print(\"length of notes after the elemination :\", len(notes))\n",
    "        if stop_flag:\n",
    "            break\n",
    "\n",
    "    count_num = Counter(notes)\n",
    "    Recurrence = list(count_num.values())\n",
    "\n",
    "    avg_r = round(average_f(Recurrence), 2)\n",
    "\n",
    "    print(\"\\naverage recurrence for a note in notes:\", avg_r)\n",
    "    print(\"most frequent note in notes appeared:\", max(Recurrence), \"times\")\n",
    "    print(\"least frequent note in notes appeared:\", min(Recurrence), \"time/s\")\n",
    "\n",
    "    del count_num, Recurrence, pitchnames, note_to_int_before, rare_note\n",
    "    gc.collect()\n",
    "\n",
    "    return notes, metadata\n",
    "\n",
    "\n",
    "def mapping(uncut_notes, metadata, sequence_len, cuts):\n",
    "\n",
    "    if cuts > 0:\n",
    "        notes, new_metadata = cut_notes(uncut_notes, metadata, cuts)\n",
    "    else:\n",
    "        notes, new_metadata = uncut_notes, metadata\n",
    "\n",
    "    sequence_length = sequence_len\n",
    "    pitchnames = set(notes)\n",
    "    note_to_int = dict((note_var, number) for number, note_var in enumerate(pitchnames))\n",
    "\n",
    "    nn_input = []\n",
    "    nn_output = []\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "\n",
    "        nn_input.append([note_to_int[char] for char in sequence_in])\n",
    "        nn_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    input_count = len(nn_input)\n",
    "    mapped_n_count = float(len(note_to_int))\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    nn_input = np.reshape(nn_input, (input_count, sequence_length, 1))\n",
    "    # normalize input and values for mapped notes\n",
    "    nn_input = nn_input / mapped_n_count\n",
    "    # for i in note_to_int:\n",
    "    #     note_to_int[i] = note_to_int[i] / mapped_n_count\n",
    "\n",
    "    nn_output = np_utils.to_categorical(nn_output)\n",
    "\n",
    "    # print metadata about notes after removing\n",
    "    info_print_out(new_metadata, len(note_to_int))\n",
    "\n",
    "    return nn_input, nn_output, note_to_int, pitchnames\n",
    "\n",
    "\n",
    "def info_print_out(metadata, unique_elements_count):\n",
    "    all_count = metadata['note_count'] + metadata['chord_count'] + metadata['rest']\n",
    "    print('\\n')\n",
    "    print('_________________________________________________')\n",
    "    print('\\n')\n",
    "    print('number of all elements:      ', all_count)\n",
    "    print('notes:    ', metadata['note_count'])\n",
    "    print('chords:   ', metadata['chord_count'])\n",
    "    print('rests:    ', metadata['rest'])\n",
    "    print('number of unique elements:   ', unique_elements_count)\n",
    "    print('\\n')\n",
    "    print('_________________________________________________')\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "def parse_MIDI_init(folder_path, sequence_length, cuts):\n",
    "    notes_and_chords, metadata_p = parse_midi_file(folder_path)                                                         # parse MIDI file\n",
    "    lstm_input, lstm_output, notes_to_int, pitch_names = mapping(notes_and_chords, metadata_p, sequence_length, cuts)   # mapping MIDI file parts\n",
    "\n",
    "    lstm_input_shuffled, lstm_output_shuffled = sklearn.utils.shuffle(lstm_input, lstm_output)                          # shuffling input and output simultaneously\n",
    "    pitch_names_len = len(pitch_names)\n",
    "\n",
    "    del notes_and_chords\n",
    "    del metadata_p\n",
    "    del lstm_input\n",
    "    del lstm_output\n",
    "    del pitch_names\n",
    "    gc.collect()\n",
    "\n",
    "    return lstm_input_shuffled, lstm_output_shuffled, notes_to_int, pitch_names_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b5a80d",
   "metadata": {},
   "source": [
    "train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28970a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(nn_input, n_pitch):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(\n",
    "        256,\n",
    "        input_shape=(nn_input.shape[1], nn_input.shape[2]),\n",
    "        return_sequences=True,\n",
    "    ))\n",
    "    lstm_model.add(Dropout(0.6))\n",
    "    lstm_model.add(LSTM(256, return_sequences=True))\n",
    "    lstm_model.add(Dropout(0.6))\n",
    "    lstm_model.add(LSTM(256))\n",
    "    lstm_model.add(Dropout(0.6))\n",
    "\n",
    "    lstm_model.add(Dense(256))\n",
    "    lstm_model.add(Dropout(0.6))\n",
    "\n",
    "    lstm_model.add(Dense(n_pitch))\n",
    "    lstm_model.add(Activation('sigmoid'))\n",
    "    lstm_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "    return lstm_model\n",
    "\n",
    "\n",
    "def load_weight_to_model(empt_model, weight):\n",
    "    filepath = f'weights\\\\toLoadWeights\\\\{weight}.hdf5'\n",
    "    try:\n",
    "        empt_model.load_weights(filepath)\n",
    "    except OSError as e:\n",
    "        print('\\nERROR loading weights file in load_weight_to_model()')\n",
    "        print(e)\n",
    "        quit()\n",
    "    return empt_model\n",
    "\n",
    "\n",
    "def train_lstm(nn, nn_input, nn_output, epochs, batch_size):\n",
    "\n",
    "    filepath = \"weights\\\\weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath, monitor='loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # print('Input shape: ' + nn_input.shape)\n",
    "    # print('Output shape: ' + nn_output.shape)\n",
    "    # print('X[0]: ', nn_input[0])\n",
    "    # print('argmax y[0]: ', np.argmax(nn_output[0]))\n",
    "    # print('argmax y[0] / 182: ', np.argmax(nn_output[0]) / float(182))\n",
    "\n",
    "    # gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    # if gpus:\n",
    "    #     try:\n",
    "    #         # Currently, memory growth needs to be the same across GPUs\n",
    "    #         for gpu in gpus:\n",
    "    #             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    #         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    #         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    #         data = nn.fit(nn_input, nn_output, epochs=250, batch_size=16, callbacks=callbacks_list)  # batch_size=64\n",
    "    #         return nn, data\n",
    "    #     except RuntimeError as e:\n",
    "    #         # Memory growth must be set before GPUs have been initialized\n",
    "    #         print(e)\n",
    "\n",
    "    # with tf.device('/GPU:0'):\n",
    "    data = nn.fit(nn_input, nn_output, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)     # batch_size=64\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    plt.plot(data.history['loss'], label=f'Loss hodnota', lw=2)\n",
    "    plt.title('Trénovanie celého datasetu')\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.135),\n",
    "              fancybox=True, shadow=True, ncol=5)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "    fig.savefig('tests\\\\cely-dataset-bs64_nieco.pdf')\n",
    "    plt.clf()\n",
    "    return nn\n",
    "\n",
    "\n",
    "def train_model_init(lstm_input, lstm_output, pitch_names_len, epochs, batch_size, model_training):\n",
    "\n",
    "    empty_model = create_lstm_model(lstm_input, pitch_names_len)                        # load layers of NN to model\n",
    "\n",
    "    if model_training[\"bool\"]:\n",
    "        model = train_lstm(empty_model, lstm_input, lstm_output, epochs, batch_size)    # train NN\n",
    "    else:\n",
    "        model = load_weight_to_model(empty_model, model_training[\"weight\"])             # load weights to model\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e8b9ab",
   "metadata": {},
   "source": [
    "generate_music.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a322b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source of this function : https://stackoverflow.com/questions/1806278/convert-fraction-to-float\n",
    "def convert_to_float(frac_str):\n",
    "    try:\n",
    "        return float(frac_str)\n",
    "    except ValueError:\n",
    "        num, denom = frac_str.split('/')\n",
    "        try:\n",
    "            leading, num = num.split(' ')\n",
    "            whole = float(leading)\n",
    "        except ValueError:\n",
    "            whole = 0\n",
    "        frac = float(num) / float(denom)\n",
    "        return whole - frac if whole < 0 else whole + frac\n",
    "\n",
    "\n",
    "def create_midi_file(output, mapping_keys, length, index, new_file_name):\n",
    "\n",
    "    unmapped_from_int = []\n",
    "    converted = []\n",
    "    notes = []\n",
    "    offset = 0\n",
    "\n",
    "    metadata = {\n",
    "        \"note\": 0,\n",
    "        \"chord\": 0,\n",
    "        \"rest\": 0\n",
    "    }\n",
    "\n",
    "    # # unmapping notes, chores and rests from output integers\n",
    "    for element in output:\n",
    "        for key in mapping_keys:\n",
    "            if int(mapping_keys.get(key)) == element:\n",
    "                unmapped_from_int.append(key)\n",
    "                break\n",
    "\n",
    "    # creating note, chores and rest objects\n",
    "    for element in unmapped_from_int:\n",
    "        if 'n_' in element:                         # note\n",
    "            element = element[2:]                                                       # cut the 'n_' mark\n",
    "            offset += Fraction(element.split('_')[2])\n",
    "            note_ = note.Note(element.split('_')[0])                                    # creating note\n",
    "            note_.duration.quarterLength = convert_to_float(element.split('_')[1])      # adding duration quarterLength\n",
    "            note_.offset = offset                                                       # adding offset\n",
    "            note_.storedInstrument = instrument.Piano()\n",
    "            converted.append(note_)                                                     # appending final array\n",
    "            metadata['note'] = metadata['note'] + 1\n",
    "\n",
    "        elif 'c_' in element:                       # chord\n",
    "            element = element[2:]                                                       # cut the 'c_' mark\n",
    "            offset += Fraction(element.split('_')[2])\n",
    "            notes_in_chord = element.split('_')[0].split('.')                           # gettig notes as string from element\n",
    "\n",
    "            notes.clear()\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(current_note)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "\n",
    "            chord_ = chord.Chord(notes)                                                 # creating chord form notes\n",
    "            chord_.duration.quarterLength = convert_to_float(element.split('_')[1])     # adding duration quarterLength\n",
    "            chord_.offset = offset                                                      # adding offset\n",
    "            converted.append(chord_)                                                    # appending final array\n",
    "            metadata['chord'] = metadata['chord'] + 1\n",
    "\n",
    "        elif 'r_' in element:                       # rest\n",
    "            element = element[2:]                                                       # cut the 'r_' mark\n",
    "            offset += Fraction(element.split('_')[1])\n",
    "            rest_ = note.Rest()                                                         # creating rest\n",
    "            rest_.duration.quarterLength = convert_to_float(element.split('_')[0])      # adding duration quarterLength\n",
    "            rest_.offset = offset                                                       # adding offset\n",
    "            rest_.storedInstrument = instrument.Piano()\n",
    "            converted.append(rest_)                                                     # appending final array\n",
    "            metadata['rest'] = metadata['rest'] + 1\n",
    "\n",
    "    print(f'\\nElements of newly generated music with index={index}: ', metadata)\n",
    "\n",
    "    try:\n",
    "        midi_stream = stream.Stream(converted)\n",
    "        midi_stream.write('midi', fp='midi_samples\\\\outputs\\\\' + f'{new_file_name}' + str(index) + '.mid') \n",
    "#         midi_stream.write('midi', fp=f'midi_samples\\outputs\\{new_file_name}{str(index)}.mid')\n",
    "        print('Created new MIDI file')\n",
    "        midi_stream.show('midi')\n",
    "    except OSError as e:\n",
    "        print('\\nERROR creating MIDI file in create_midi_file()')\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def generate_music(nn_model, nn_input, mapped_notes, length):\n",
    "\n",
    "    generated_music = []\n",
    "    sequence_len = len(nn_input[0])\n",
    "    mapped_notes_count = len(mapped_notes)\n",
    "    start = np.random.randint(0, len(nn_input) - 1)\n",
    "    # int_to_notes = {v: k for k, v in mapped_notes.items()}\n",
    "    pattern = nn_input[start]\n",
    "\n",
    "    note_input = np.array(pattern).reshape((1, sequence_len, 1))\n",
    "    note_input = note_input / float(mapped_notes_count)\n",
    "    # note_input = note_inputQ / float(mapped_notes_count)\n",
    "\n",
    "    for new_note in range(length):\n",
    "        note_output = nn_model.predict(note_input, verbose=0)\n",
    "        note_output_max = np.argmax(note_output)\n",
    "        generated_music.append(note_output_max)\n",
    "\n",
    "        pattern = np.append(pattern, note_output_max / float(mapped_notes_count))\n",
    "        pattern = pattern[1:sequence_len + 1]\n",
    "\n",
    "        note_input = np.array(pattern).reshape((1, sequence_len, 1))\n",
    "\n",
    "    return generated_music\n",
    "\n",
    "\n",
    "def generate_music_init(model, lstm_input, notes_to_int, length, index, new_file_name):\n",
    "    new_music = generate_music(model, lstm_input, notes_to_int, length)         # predict new music\n",
    "    create_midi_file(new_music, notes_to_int, length, index, new_file_name)     # save new music to MIDI file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23a802",
   "metadata": {},
   "source": [
    "main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c10286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 5697\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 4936\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 7016\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 6795\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 2939\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 6639\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 10124\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 4899\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 5015\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 8380\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 2384\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 11519\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 10024\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 4074\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 6876\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 6647\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 3577\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 1805\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 8176\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 3645\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano right>\n",
      "^elems_count: 5\n",
      "parsing PIANO <music21.stream.Part Piano>\n",
      "^elems_count: 4303\n",
      "parsing PIANO <music21.stream.Part Piano left>\n",
      "^elems_count: 5\n",
      "MIDI dataset:\n",
      " ['mz_311_1.mid', 'mz_311_2.mid', 'mz_311_3.mid', 'mz_330_1.mid', 'mz_330_2.mid', 'mz_330_3.mid', 'mz_331_1.mid', 'mz_331_2.mid', 'mz_331_3.mid', 'mz_332_1.mid', 'mz_332_2.mid', 'mz_332_3.mid', 'mz_333_1.mid', 'mz_333_2.mid', 'mz_333_3.mid', 'mz_545_1.mid', 'mz_545_2.mid', 'mz_545_3.mid', 'mz_570_1.mid', 'mz_570_2.mid', 'mz_570_3.mid']\n",
      "\n",
      "number of notes before: 76032\n",
      "number of unique notes before: 4583\n",
      "average recurrence for a note in notes: 16.59\n",
      "most frequent note in notes appeared: 4286 times\n",
      "least frequent note in notes appeared: 1 time/s\n",
      "number of notes occuring less than 17 times: 4133\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    start_time = time.time()\n",
    "    print('Num GPUs Available: ', len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    sequence_length = int(config[\"sequence_length\"])\n",
    "    midi_files_folder = 'midi_samples\\\\' + config[\"dataset_folder\"] + '\\\\'\n",
    "    cuts = int(config[\"cuts\"])\n",
    "    epochs = int(config[\"epochs\"])\n",
    "    batch_size = int(config[\"batch_size\"])\n",
    "    new_music_length = int(config[\"new_music_length\"])\n",
    "    tracks_to_generate = int(config[\"tracks_to_generate\"])\n",
    "    new_music_file_name = config[\"new_music_file_name\"]\n",
    "    model_training = config[\"training\"]\n",
    "\n",
    "    lstm_input, lstm_output, notes_to_int, pitch_names_len = parse_MIDI_init(midi_files_folder, sequence_length, cuts)\n",
    "    model = train_model_init(lstm_input, lstm_output, pitch_names_len, epochs, batch_size, model_training)\n",
    "\n",
    "    for i in range(tracks_to_generate):\n",
    "        generate_music_init(model, lstm_input, notes_to_int, new_music_length, i, new_music_file_name)\n",
    "\n",
    "    # generate_music.init(model, lstm_input, notes_to_int, 100)\n",
    "    # generate_music.init(model, lstm_input, notes_to_int, 150)\n",
    "    # generate_music.init(model, lstm_input, notes_to_int, 200)\n",
    "    # generate_music.init(model, lstm_input, notes_to_int, 250)\n",
    "    # generate_music.init(model, lstm_input, notes_to_int, 300)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print('Time:', int(end_time - start_time), 's')\n",
    "    print('\\n--- END ---\\n')\n",
    "    # model.summary()\n",
    "\n",
    "except OSError as e:\n",
    "    print('\\nERROR loading config file in main.py')\n",
    "    print(e)\n",
    "    quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
